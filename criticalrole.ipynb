{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3973106c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-08-01T22:01:55.199996Z",
     "iopub.status.busy": "2022-08-01T22:01:55.199030Z",
     "iopub.status.idle": "2022-08-01T22:02:02.370661Z",
     "shell.execute_reply": "2022-08-01T22:02:02.369074Z"
    },
    "papermill": {
     "duration": 7.18076,
     "end_time": "2022-08-01T22:02:02.373393",
     "exception": false,
     "start_time": "2022-08-01T22:01:55.192633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0a48dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T22:02:02.380311Z",
     "iopub.status.busy": "2022-08-01T22:02:02.379694Z",
     "iopub.status.idle": "2022-08-01T22:02:02.705916Z",
     "shell.execute_reply": "2022-08-01T22:02:02.704851Z"
    },
    "papermill": {
     "duration": 0.332556,
     "end_time": "2022-08-01T22:02:02.708532",
     "exception": false,
     "start_time": "2022-08-01T22:02:02.375976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 22:02:02.442284: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FILE_PATH = \"/kaggle/input/modified-critical-role-scripts/script.txt\"\n",
    "\n",
    "IS_DEBUG = False\n",
    "SAVE_MODEL = False\n",
    "\n",
    "text = open(FILE_PATH, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "ids_from_chars = preprocessing.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "\n",
    "chars_from_ids = preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None\n",
    ")\n",
    "\n",
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
    "\n",
    "\n",
    "def split_input_sequence(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)\n",
    "\n",
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "dataset = sequences.map(split_input_sequence)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "EPOCHS = 40\n",
    "\n",
    "if IS_DEBUG:\n",
    "    EPOCHS = 1\n",
    "\n",
    "embedding_dim = 256\n",
    "rnn_units = 2048\n",
    "\n",
    "dataset = (\n",
    "    dataset.shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5aab155",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T22:02:02.715306Z",
     "iopub.status.busy": "2022-08-01T22:02:02.714924Z",
     "iopub.status.idle": "2022-08-01T22:02:02.906415Z",
     "shell.execute_reply": "2022-08-01T22:02:02.905630Z"
    },
    "papermill": {
     "duration": 0.197589,
     "end_time": "2022-08-01T22:02:02.908643",
     "exception": false,
     "start_time": "2022-08-01T22:02:02.711054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CriticalRoleModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            rnn_units, return_sequences=True, return_state=True\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "model = CriticalRoleModel(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    ")\n",
    "\n",
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df346eff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-01T22:02:02.915595Z",
     "iopub.status.busy": "2022-08-01T22:02:02.914089Z",
     "iopub.status.idle": "2022-08-02T01:18:24.040636Z",
     "shell.execute_reply": "2022-08-02T01:18:24.039852Z"
    },
    "papermill": {
     "duration": 11781.20296,
     "end_time": "2022-08-02T01:18:24.113952",
     "exception": false,
     "start_time": "2022-08-01T22:02:02.910992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-01 22:02:08.909299: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 276s 8s/step - loss: 3.9119 - accuracy: 0.1862\n",
      "Epoch 2/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 2.4963 - accuracy: 0.3425\n",
      "Epoch 3/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 2.1005 - accuracy: 0.4124\n",
      "Epoch 4/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 1.9349 - accuracy: 0.4447\n",
      "Epoch 5/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 1.8217 - accuracy: 0.4692\n",
      "Epoch 6/40\n",
      "35/35 [==============================] - 265s 8s/step - loss: 1.7154 - accuracy: 0.4969\n",
      "Epoch 7/40\n",
      "35/35 [==============================] - 264s 8s/step - loss: 1.6209 - accuracy: 0.5215\n",
      "Epoch 8/40\n",
      "35/35 [==============================] - 265s 8s/step - loss: 1.5334 - accuracy: 0.5423\n",
      "Epoch 9/40\n",
      "35/35 [==============================] - 264s 8s/step - loss: 1.4497 - accuracy: 0.5652\n",
      "Epoch 10/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 1.3754 - accuracy: 0.5846\n",
      "Epoch 11/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 1.3035 - accuracy: 0.6048\n",
      "Epoch 12/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 1.2295 - accuracy: 0.6252\n",
      "Epoch 13/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 1.1616 - accuracy: 0.6441\n",
      "Epoch 14/40\n",
      "35/35 [==============================] - 269s 8s/step - loss: 1.0925 - accuracy: 0.6628\n",
      "Epoch 15/40\n",
      "35/35 [==============================] - 270s 8s/step - loss: 1.0209 - accuracy: 0.6837\n",
      "Epoch 16/40\n",
      "35/35 [==============================] - 269s 8s/step - loss: 0.9467 - accuracy: 0.7046\n",
      "Epoch 17/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 0.8709 - accuracy: 0.7281\n",
      "Epoch 18/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 0.7844 - accuracy: 0.7562\n",
      "Epoch 19/40\n",
      "35/35 [==============================] - 265s 8s/step - loss: 0.6992 - accuracy: 0.7845\n",
      "Epoch 20/40\n",
      "35/35 [==============================] - 270s 8s/step - loss: 0.6057 - accuracy: 0.8174\n",
      "Epoch 21/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 0.5212 - accuracy: 0.8462\n",
      "Epoch 22/40\n",
      "35/35 [==============================] - 270s 8s/step - loss: 0.4392 - accuracy: 0.8740\n",
      "Epoch 23/40\n",
      "35/35 [==============================] - 269s 8s/step - loss: 0.3633 - accuracy: 0.8994\n",
      "Epoch 24/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.3052 - accuracy: 0.9172\n",
      "Epoch 25/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 0.2588 - accuracy: 0.9311\n",
      "Epoch 26/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 0.2180 - accuracy: 0.9427\n",
      "Epoch 27/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 0.1876 - accuracy: 0.9504\n",
      "Epoch 28/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.1621 - accuracy: 0.9572\n",
      "Epoch 29/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 0.1412 - accuracy: 0.9630\n",
      "Epoch 30/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.1274 - accuracy: 0.9663\n",
      "Epoch 31/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.1148 - accuracy: 0.9698\n",
      "Epoch 32/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.1024 - accuracy: 0.9730\n",
      "Epoch 33/40\n",
      "35/35 [==============================] - 269s 8s/step - loss: 0.0937 - accuracy: 0.9750\n",
      "Epoch 34/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.0872 - accuracy: 0.9763\n",
      "Epoch 35/40\n",
      "35/35 [==============================] - 268s 8s/step - loss: 0.0816 - accuracy: 0.9777\n",
      "Epoch 36/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 0.0764 - accuracy: 0.9785\n",
      "Epoch 37/40\n",
      "35/35 [==============================] - 265s 8s/step - loss: 0.0733 - accuracy: 0.9791\n",
      "Epoch 38/40\n",
      "35/35 [==============================] - 261s 7s/step - loss: 0.0708 - accuracy: 0.9795\n",
      "Epoch 39/40\n",
      "35/35 [==============================] - 266s 8s/step - loss: 0.0694 - accuracy: 0.9797\n",
      "Epoch 40/40\n",
      "35/35 [==============================] - 267s 8s/step - loss: 0.0685 - accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06476bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T01:18:24.260804Z",
     "iopub.status.busy": "2022-08-02T01:18:24.260387Z",
     "iopub.status.idle": "2022-08-02T01:18:24.270365Z",
     "shell.execute_reply": "2022-08-02T01:18:24.269580Z"
    },
    "papermill": {
     "duration": 0.085601,
     "end_time": "2022-08-02T01:18:24.272258",
     "exception": false,
     "start_time": "2022-08-02T01:18:24.186657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OneStepModel(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "\n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values=[-float(\"inf\")] * len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_chars.get_vocabulary())],\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "        # Run the model.\n",
    "        # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(\n",
    "            inputs=input_ids, states=states, return_state=True\n",
    "        )\n",
    "        # Only use the last prediction.\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits\n",
    "        # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        # Sample the output logits to generate token IDs.\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # Convert from token ids to characters\n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "        # Return the characters and model state.\n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22d8f098",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-08-02T01:18:24.421315Z",
     "iopub.status.busy": "2022-08-02T01:18:24.420588Z",
     "iopub.status.idle": "2022-08-02T01:18:26.140518Z",
     "shell.execute_reply": "2022-08-02T01:18:26.138710Z"
    },
    "papermill": {
     "duration": 1.798361,
     "end_time": "2022-08-02T01:18:26.143040",
     "exception": false,
     "start_time": "2022-08-02T01:18:24.344679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n",
      "MATT: That ends your turn?\r\n",
      "\r\n",
      "MARISHA: Yep.\r\n",
      "\r\n",
      "MATT: All righty, where do you want it to go?\r\n",
      "\r\n",
      "LAURA: Wait. Wouldn't it be funny if that was\r\n",
      "Marius?\r\n",
      "\r\n",
      "M\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStepModel(model, chars_from_ids, ids_from_chars)\n",
    "\n",
    "states = None\n",
    "\n",
    "next_char = tf.constant([\"MATT:\"])\n",
    "result = [next_char]\n",
    "\n",
    "length = 150\n",
    "\n",
    "for n in range(length):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "\n",
    "\n",
    "# file = open(\"generated.txt\", \"w\")\n",
    "\n",
    "# file.write(result[0].numpy().decode(\"utf-8\"))\n",
    "\n",
    "# file.close()\n",
    "\n",
    "print(\"Finished!\")\n",
    "\n",
    "print(result[0].numpy().decode(\"utf-8\"))\n",
    "\n",
    "print( \"\\n\\n\" + \"_\" * 80 + \"\\n\\n\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11802.884184,
   "end_time": "2022-08-02T01:18:28.916290",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-01T22:01:46.032106",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
